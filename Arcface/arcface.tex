\documentclass[a4paper]{article}

\usepackage[]{amsmath, amsthm, amsfonts}
\usepackage[scale = 0.8]{geometry}
\usepackage[]{algorithmic}

\begin{document}

\newcommand{\bb}[1]{\mathbb{#1}}

\section{Arcface}

Softmax loss:
\begin{align*}
    L_1 = -\frac{1}{N} \sum_{i=1}^N \log \frac{\exp(W_{y_i} \cdot x_i + b_{y_i})}{
        \sum_{j=1}^n \exp(W_j \cdot x_i + b_j)}
\end{align*}
where
\begin{table}[ht]
\caption{Explanation}
\centering
\begin{tabular}{c c}
    $N$ & batch size \\
    $n$ & number of classes \\
    $x_i \in \bb{R}^d$ & $i$-th sample's embedding \\
    $y_i$ & Its class \\
    $W \in \bb{R}^{d \times n}$ & Weight Matrix \\
    $b_j \in \bb{R}^n$ & Biased term \\
\end{tabular}
\end{table}

$L_2$ normalization on $W$, $x_i$

\end{document}