\documentclass{report}

\usepackage{amsmath, amsfonts, amsthm}
\usepackage[scale = 0.8]{geometry}
\usepackage[shortlabels]{enumitem}
\def\ve{\varepsilon}
\def\floor#1{\lfloor{} #1 \rfloor{}}
\def\abs#1{\left| #1 \right|}
\def\slash{\backslash{}}
\def\p{\partial}

\begin{document}
    \section*{Problem 1}
    Let $S_n(x) = \sum_{k=1}^n f_k(x)$. For $m \ge n$,
    \begin{align*}
        \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k g_k &= \sum_{k=n}^{m-1}S_k(g_k-g_{k+1})
            + (S_m g_m - S_n g_n) 
    \end{align*}
    $|S_k| \le C$ and $g_k - g_{k+1} \ge 0$ for any $k \in \mathbb{N}$. 
    Since $g_k$ converges to 0 and is monotonically decreasing, $g_m > 0, g_n > 0$. 
    Therefore we have:
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k\right| \le \sum_{k=n}^{m-1} C (g_k-g_{k+1}) + 
            C(g_m + g_n) = 2Cg_n
    \end{align*}
    Since $g_n$ converges uniformly on $E$ to 0, for any $\varepsilon > 0$, there 
    exist $N(\varepsilon)$ such that for $n \ge N$, we have $g_n<\frac{\varepsilon}{2C}$.
    Thus we conclude that for $N \le n \le m$, 
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k g_k\right| \le 2Cg_n < \varepsilon
    \end{align*}
    Since it holds for every $x \in E$, we have 
    \begin{align*}
        \left\| \sum_{k=1}^m f_k g_k-\sum_{k=1}^n f_k g_k \right\|_E \le 2Cg_n < \ve
    \end{align*}
    By cauchy criterion, it converges uniformly.
    
    \section*{Problem 2}
    Let $R_n(x) = \sum_{k=n}^\infty f_n (x)$, because $\sum_{k=1}^\infty f_n$ converges.
    For $m \ge n$,
    \begin{align*}
        \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k g_k &= 
            R_n g_n - R_{m+1} g_m + \sum_{k=n}^{m-1}R_{k+1} (g_{k+1} - g_k)
    \end{align*}
    Since $g_{k} \ge g_{k+1}$, we have:
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k, g_k \right| &\le
            |R_n| |g_n| + |R_{m+1}| |g_m| + \sum_{k=n}^{m-1} |R_{k+1}| (g_k - g_{k+1})
    \end{align*}
    Since $\sum_{k=1}^\infty f_n$ converges uniformly on $E$, for any $\ve > 0$,
    there exist $N$ such that for $n > N$,
    we have $|R_n| \le \frac{\ve}{4C}$. Also since $g_k$ is bounded by $C$,
    we have
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_j g_k \right| &\le 
            C \cdot \frac{\ve}{4C} \cdot 2 + \frac{\ve}{4C} \sum_{k=n}^{m-1} 
            (g_k - g_{k+1}) \\
            &= \frac{\ve}{2} + \frac{\ve}{4C} (g_n - g_m) \\
            &\le \frac{\ve}{2} + \frac{\ve}{4C} (|g_n|+g_m|) \le \ve
    \end{align*}
    By cauchy criterion, this implies uniform convergence.

    \section*{Problem 3}
    \begin{enumerate}[(a)]
        \item 
        $\frac{1}{n} \ge \frac{1}{n+1}$ for any $n$, and 
        $\frac{1}{n}$ converges uniformly to zero. For $\sin nx$, we have:
        \begin{align*}
            \left| \sum_{k=1}^n \sin kx \right| &= \left| \frac{\sin\frac{kx+x}{2}
            \sin\frac{kx}{2}}{\sin\frac{x}{2}} \right| \\
            &\le\frac{1}{\left|\sin\frac{x}{2} \right|}
        \end{align*}
        since $x \in [\ve, 2\pi - \ve]$ where $\ve > 0$, $\sin \frac{x}{2} \ge \sin
        \frac{\ve}{2} > 0$. Therefore $\frac{1}{\left|\sin\frac{x}{2} \right|}$ is bounded
        by $\frac{1}{\left|\sin\frac{\ve}{2} \right|}$. By Dirichlet's test, it converges
        uniformly on $[\ve, 2\pi - \ve], \ve > 0$.
        \item 
        By alternating series test, $\sum_{n=1}^\infty \frac{{(-1)}^n}{n}$ converges.
        Also $x^n \ge x^{n+1}$ for $x \in [0,1]$ and $|x^n| \le 1$ for and $n\in\mathbb{N}
        $ and $x \in [0, 1]$. By Abel's test, it converges uniformly on $[0, 1]$.
        \item 
        By integral test, 
        \begin{align*}
            \int_2^\infty \frac{dx}{x {(\log x)}^2} &= -\frac{1}{\log(x)} \bigg|_2^\infty \\
            &= \frac{1}{\log 2} < \infty
        \end{align*}
        Therefore $\sum_{k=2}^\infty \frac{1}{k{(\log k)}^2}$ converges.
        And since $\bigg|\frac{x^k}{k{(\log k)}^2}\bigg| \le \frac{1}{k{(\log k)}^2}$ for 
        $x \in [-1, 1]$, by Weiestrass' M-test, it converges uniformly on $[-1, 1]$.
    \end{enumerate}

    \section*{Problem 4}
    \begin{enumerate}[(a)]
    
    \item
    \begin{align*}
        \int_0^1 t^{x-1} e^{-t} dt &= \int_0^1 \sum_{n=0}^\infty 
            \frac{{(-1)}^n t^{n+x-1}}{n!} dt
    \end{align*}
    Because $x > 1$ and $t \in [0, 1]$, 
    \begin{align*}
        \frac{{(-1)}^n t^{n+x-1}}{n!} &\le \frac{t^{n+x-1}}{n!} 
        \le \frac{t^{n}}{n!} \le t^{n}
    \end{align*}
    and $\sum_{n=0}^\infty t^{n}$ converges. Therefore Weierstrass' M-test shows the 
    series $\sum_{n=0}^\infty \frac{{(-1)}^n t^{n+x-1}}{n!}$ converges uniformly on 
    $t \in [0, 1]$. So we can 
    \begin{align*}
        \int_0^1 t^{x-1} e^{-t} dt &=  \sum_{n=0}^\infty 
            \int_0^1\frac{{(-1)}^n t^{n+x-1}}{n!} dt \\
            &= \sum_{n=0}^n \frac{{(-1)}^n}{n! (x+n)}
    \end{align*}

    \item
    Let $D := R \slash \bigcup_{n=0}^\infty(-n-\ve, -n+\ve)$ for any small $\ve > 0$.
    Then for $x \in D$, $\abs{x+n} \ge \ve$ for any $n \in \mathbb{N}$.
    \begin{align*}
        \frac{{(-1)}^n}{n! (x+n)} &\le \frac{1}{n!\abs{x+n}} \\
        &\le \frac{1}{n!\ve}
    \end{align*}
    By ratio test, $L = \lim_{n \to \infty} \frac{1}{n+1} = 0 < 1$, 
    $\sum_{n=0}^\infty\frac{1}{n!\ve}$ converges. Then $g(x)$ converges uniformly on $D$.
    Because $\sum_{n=0}^N \frac{{{(-1)}^n}}{n!(x+n)}$ is continuous for $N \in \mathbb{N}$, 
    it defines a continuous function on $D$ for any $\ve$, hence it is also a continuous 
    function on $\Omega$ as $\ve \to 0$.
    \end{enumerate}

    \section*{Problem 5}
    Since $f(t, x)$ is $C^\infty, \frac{\p}{\p t} \frac{\p^k f}{\p x^k} (t, x)$ is 
    continuous for any $(t, x) \in [0, T) \times [a,b]$ and any $k \in \mathbb{N} \cup \{0\}$.
    For $p< q \in [T - \ve, T)$, $\forall \ve > 0$,
    \begin{align*}
        \abs{\frac{\p^k}{\p x^k}f(q, x) - \frac{\p^k}{\p x^k}f(p, x)} &= 
            \abs{\int_p^q \frac{d}{dt} \frac{\p^k}{\p x^k}f(t, x) dt}\\
            &\le \abs{q-p} C_k \le \ve C_k
    \end{align*} 
    Thus $g(x) = \lim_{t \to T^{-}} f(t,x)$ exists for every $x$ as it is the case for $k = 0$.
    Since $f$ is continuous over all order derivatives, and $x$ it independent of $t$, we also have
    \begin{align*}
        \frac{d^k}{dx^k}g(x) &= \frac{d^k}{dx^k} \lim_{t \to T^-} f(t, x) \\
            &= \lim_{t \to T^-} \frac{d^k}{dx^k} f(t, x)
    \end{align*}
    Hence for a fixed $k$, $\forall \ve > 0$, as $x \to x_0 \in [a, b], t \to T^-$,
    \begin{align*}
        \abs{\frac{d^k}{dx^k}g(x) - \frac{d^k}{dx^k} f(t, x)} &< \ve \\
        \abs{\frac{d^k}{dx^k}g(x_0) - \frac{d^k}{dx^k} f(t, x_0)} &< \ve \\
        \abs{\frac{d^k}{dx^k} f(t, x) - \frac{d^k}{dx^k} f(t, x_0)} &< \ve
    \end{align*}
    By triangular inequality, $\abs{\frac{d^k}{dx^k}g(x) - \frac{d^k}{dx^k}g(x_0)} < 3\ve$.
    Thus $g(x)$ is $C^k$. Since it is true for any $k$, $g(x)$ is $C^\infty$.

    \section*{Problem 6}
    
    
\end{document}