\documentclass{report}

\usepackage{amsmath, amsfonts, amsthm}
\usepackage[scale = 0.8]{geometry}
\usepackage[shortlabels]{enumitem}
\def\ve{\varepsilon}
\def\floor#1{\lfloor{} #1 \rfloor{}}
\def\abs#1{\left| #1 \right|}
\def\slash{\backslash{}}
\def\p{\partial}

\begin{document}
    \section*{Problem 1}
    Let $S_n(x) = \sum_{k=1}^n f_k(x)$. For $m \ge n$,
    \begin{align*}
        \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k g_k &= \sum_{k=n}^{m-1}S_k(g_k-g_{k+1})
            + (S_m g_m - S_n g_n) 
    \end{align*}
    $|S_k| \le C$ and $g_k - g_{k+1} \ge 0$ for any $k \in \mathbb{N}$. 
    Since $g_k$ converges to 0 and is monotonically decreasing, $g_m > 0, g_n > 0$. 
    Therefore we have:
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k\right| \le \sum_{k=n}^{m-1} C (g_k-g_{k+1}) + 
            C(g_m + g_n) = 2Cg_n
    \end{align*}
    Since $g_n$ converges uniformly on $E$ to 0, for any $\varepsilon > 0$, there 
    exist $N(\varepsilon)$ such that for $n \ge N$, we have $g_n<\frac{\varepsilon}{2C}$.
    Thus we conclude that for $N \le n \le m$, 
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k g_k\right| \le 2Cg_n < \varepsilon
    \end{align*}
    Since it holds for every $x \in E$, we have 
    \begin{align*}
        \left\| \sum_{k=1}^m f_k g_k-\sum_{k=1}^n f_k g_k \right\|_E \le 2Cg_n < \ve
    \end{align*}
    By cauchy criterion, it converges uniformly.
    
    \section*{Problem 2}
    Let $R_n(x) = \sum_{k=n}^\infty f_n (x)$, because $\sum_{k=1}^\infty f_n$ converges.
    For $m \ge n$,
    \begin{align*}
        \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k g_k &= 
            R_n g_n - R_{m+1} g_m + \sum_{k=n}^{m-1}R_{k+1} (g_{k+1} - g_k)
    \end{align*}
    Since $g_{k} \ge g_{k+1}$, we have:
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_k, g_k \right| &\le
            |R_n| |g_n| + |R_{m+1}| |g_m| + \sum_{k=n}^{m-1} |R_{k+1}| (g_k - g_{k+1})
    \end{align*}
    Since $\sum_{k=1}^\infty f_n$ converges uniformly on $E$, for any $\ve > 0$,
    there exist $N$ such that for $n > N$,
    we have $|R_n| \le \frac{\ve}{4C}$. Also since $g_k$ is bounded by $C$,
    we have
    \begin{align*}
        \left| \sum_{k=1}^m f_k g_k - \sum_{k=1}^n f_j g_k \right| &\le 
            C \cdot \frac{\ve}{4C} \cdot 2 + \frac{\ve}{4C} \sum_{k=n}^{m-1} 
            (g_k - g_{k+1}) \\
            &= \frac{\ve}{2} + \frac{\ve}{4C} (g_n - g_m) \\
            &\le \frac{\ve}{2} + \frac{\ve}{4C} (|g_n|+g_m|) \le \ve
    \end{align*}
    By cauchy criterion, this implies uniform convergence.

    \section*{Problem 3}
    \begin{enumerate}[(a)]
        \item 
        $\frac{1}{n} \ge \frac{1}{n+1}$ for any $n$, and 
        $\frac{1}{n}$ converges uniformly to zero. For $\sin nx$, we have:
        \begin{align*}
            \left| \sum_{k=1}^n \sin kx \right| &= \left| \frac{\sin\frac{kx+x}{2}
            \sin\frac{kx}{2}}{\sin\frac{x}{2}} \right| \\
            &\le\frac{1}{\left|\sin\frac{x}{2} \right|}
        \end{align*}
        since $x \in [\ve, 2\pi - \ve]$ where $\ve > 0$, $\sin \frac{x}{2} \ge \sin
        \frac{\ve}{2} > 0$. Therefore $\frac{1}{\left|\sin\frac{x}{2} \right|}$ is bounded
        by $\frac{1}{\left|\sin\frac{\ve}{2} \right|}$. By Dirichlet's test, it converges
        uniformly on $[\ve, 2\pi - \ve], \ve > 0$.
        \item 
        By alternating series test, $\sum_{n=1}^\infty \frac{{(-1)}^n}{n}$ converges.
        Also $x^n \ge x^{n+1}$ for $x \in [0,1]$ and $|x^n| \le 1$ for and $n\in\mathbb{N}
        $ and $x \in [0, 1]$. By Abel's test, it converges uniformly on $[0, 1]$.
        \item 
        By integral test, 
        \begin{align*}
            \int_2^\infty \frac{dx}{x {(\log x)}^2} &= -\frac{1}{\log(x)} \bigg|_2^\infty \\
            &= \frac{1}{\log 2} < \infty
        \end{align*}
        Therefore $\sum_{k=2}^\infty \frac{1}{k{(\log k)}^2}$ converges.
        And since $\bigg|\frac{x^k}{k{(\log k)}^2}\bigg| \le \frac{1}{k{(\log k)}^2}$ for 
        $x \in [-1, 1]$, by Weiestrass' M-test, it converges uniformly on $[-1, 1]$.
    \end{enumerate}

    \section*{Problem 4}
    \begin{enumerate}[(a)]
    
    \item
    \begin{align*}
        \int_0^1 t^{x-1} e^{-t} dt &= \int_0^1 \sum_{n=0}^\infty 
            \frac{{(-1)}^n t^{n+x-1}}{n!} dt
    \end{align*}
    Because $x > 1$ and $t \in [0, 1]$, 
    \begin{align*}
        \frac{{(-1)}^n t^{n+x-1}}{n!} &\le \frac{t^{n+x-1}}{n!} 
        \le \frac{t^{n}}{n!} \le t^{n}
    \end{align*}
    and $\sum_{n=0}^\infty t^{n}$ converges. Therefore Weierstrass' M-test shows the 
    series $\sum_{n=0}^\infty \frac{{(-1)}^n t^{n+x-1}}{n!}$ converges uniformly on 
    $t \in [0, 1]$. So we can 
    \begin{align*}
        \int_0^1 t^{x-1} e^{-t} dt &=  \sum_{n=0}^\infty 
            \int_0^1\frac{{(-1)}^n t^{n+x-1}}{n!} dt \\
            &= \sum_{n=0}^n \frac{{(-1)}^n}{n! (x+n)}
    \end{align*}

    \item
    Let $D := R \slash \bigcup_{n=0}^\infty(-n-\ve, -n+\ve)$ for any small $\ve > 0$.
    Then for $x \in D$, $\abs{x+n} \ge \ve$ for any $n \in \mathbb{N}$.
    \begin{align*}
        \frac{{(-1)}^n}{n! (x+n)} &\le \frac{1}{n!\abs{x+n}} \\
        &\le \frac{1}{n!\ve}
    \end{align*}
    By ratio test, $L = \lim_{n \to \infty} \frac{1}{n+1} = 0 < 1$, 
    $\sum_{n=0}^\infty\frac{1}{n!\ve}$ converges. Then $g(x)$ converges uniformly on $D$.
    Because $\sum_{n=0}^N \frac{{{(-1)}^n}}{n!(x+n)}$ is continuous for $N \in \mathbb{N}$, 
    it defines a continuous function on $D$ for any $\ve$, hence it is also a continuous 
    function on $\Omega$ as $\ve \to 0$.
    \end{enumerate}

    \section*{Problem 5}
    Since $f(t, x)$ is $C^\infty, \frac{\p}{\p t} \frac{\p^k f}{\p x^k} (t, x)$ is 
    continuous for any $(t, x) \in [0, T) \times [a,b]$ and any $k \in \mathbb{N} \cup \{0\}$.
    For $p< q \in [T - \ve, T)$, $\forall \ve > 0$,
    \begin{align*}
        \abs{\frac{\p^k}{\p x^k}f(q, x) - \frac{\p^k}{\p x^k}f(p, x)} &= 
            \abs{\int_p^q \frac{d}{dt} \frac{\p^k}{\p x^k}f(t, x) dt}\\
            &\le \abs{q-p} C_k \le \ve C_k
    \end{align*} 
    By cauchy condition,
    $g(x) = \lim_{t \to T^{-}} f(t,x)$ exists for every $x$ as it is the case for $k = 0$.
    Since $f$ is continuous over all order derivatives, and $x$ it independent of $t$, we also have
    \begin{align*}
        \frac{d^k}{dx^k}g(x) &= \frac{d^k}{dx^k} \lim_{t \to T^-} f(t, x) \\
            &= \lim_{t \to T^-} \frac{d^k}{dx^k} f(t, x)
    \end{align*}
    Hence for a fixed $k$, $\forall \ve > 0$, as $x \to x_0 \in [a, b], t \to T^-$,
    \begin{align*}
        \abs{\frac{d^k}{dx^k}g(x) - \frac{d^k}{dx^k} f(t, x)} &< \ve \\
        \abs{\frac{d^k}{dx^k}g(x_0) - \frac{d^k}{dx^k} f(t, x_0)} &< \ve \\
        \abs{\frac{d^k}{dx^k} f(t, x) - \frac{d^k}{dx^k} f(t, x_0)} &< \ve
    \end{align*}
    By triangular inequality, $\abs{\frac{d^k}{dx^k}g(x) - \frac{d^k}{dx^k}g(x_0)} < 3\ve$.
    Thus $g(x)$ is $C^k$. Since it is true for any $k$, $g(x)$ is $C^\infty$.

    \section*{Problem 6}
    \begin{enumerate}[(a)]
    \item

    In order to show that $\bigcup_{n=1}^\infty S_n \supset C[0, 1] - E$, it suffices to 
    show that fix $f \in C[0,1] - E$, $f \in \bigcup_{n=1}^\infty S_n$.
    For $f \in C[0,1]-E$, there exist $x_0 \in [0,1]$ such that $f^\prime(x_0)$ exists. 
    Let $g(x) = \frac{f(x) - f(x_0)}{x-x_0}$, therefore
    \begin{align*}
        \abs{\lim_{x \to x_0} g(x)} = L < +\infty
    \end{align*}
    So $\forall \ve > 0, \exists \delta(\ve) > 0 \text{ s.t. } |x-x_0| < \delta \implies 
    L - \ve < g(x) < L + \ve$. So for $x \in [0,1], x \in (x_0 - \delta, x_0 + \delta) \slash {x_0}$, 
    there exist $n \in \mathbb{N}$ such that $g(x) < L + \ve < n$. If $x = x_0$, then any 
    $n > 0$ could satisfy.

    Since $f$ is continuous on a closed interval, it is bounded, therefore $|f(x) - f(x_0)
    |< M$ for some $M > 0$. So for $x \in [0,1], x \notin (x_0 - \delta, x_0 + \delta)$,
    there also exist $n$ such that $g(x) < \frac{M}{\delta} < n$, where $n$ depends only
    on $\delta$. Thus $f \in \bigcup_{n=1}^\infty S_n$

    \item 
    Let $f_k$ be a sequence in $S_n$ converging to some $f \in C[0,1]$. 
    For each $k$, there exist $x_k$ such that for any $x \in [0,1]$,
    \begin{align*}
        \abs{\frac{f_k(x) - f_k(x_k)}{x - x_k}} \le n
    \end{align*}
    By Bolzano-Weiestrass theorem, $\{x_k\}$ has a subsequence converging to $x_\infty$.
    extract the subsequence $\{x_{k_j}\}$ and $\{f_{k_j}\}$. we got 
    \begin{align*}
        \abs{\frac{f(x) - f(x_\infty)}{x-x_\infty}} &=
            \lim_{j \to \infty} \abs{\frac{f_{k_j}(x) - f_{k_j}(x_{k_j})}{x - x_{k_j}}} \le n
    \end{align*}
    Thus $f \in S_n$ and thus $S_n$ is closed.

    \item 
    To show $S_n^o = \phi$, it suffices to show that $C[0,1] - S_n$ is dense. 
    Let $f \in C[0,1]$.
    Since $C[0,1]$ is compact, $f$ is uniformly continuous on $C[0,1]$, thus 
    $\forall \ve > 0, \exists \delta > 0, \forall x, y \in [0, 1], 
    |x - y| < \delta \implies |f(x) - f(y)| < \ve$.
    Divide $[0,1]$ in to more than $\frac{1}{\delta}$ intervals $n$:
    $[0, x_1], [x_1, x_2], \ldots [x_{n-1}, x_n]$ such that $\abs{x_i - x_{i+1}} < \delta$.
    Define $g(x)$ to be $g(x_i) = f(x_i)$, $|g^\prime(x)| > n$ and $|g(x) - f(x)| < \ve / 2$.
    We can make $g$ to be piecewise linear with absolute slope greater than $n$, 
    and we can arbitrary change the slope sign so that the first and third condition can be satisfied.
    (like a chainsaw).
    Therefore $\left\| f - h\right\|_{C[0,1]}  \le \ve$, and $g \in C[0,1] - S_n$, thus it 
    is dense and $S_n^o = \phi$.

    \item 
    According to Baire Category theorem, $\overline{C[0, 1] - \bigcup_{n=1}^\infty S_n} = C[0,1]$,
    thus $C[0, 1] - \bigcup_{n=1}^\infty S_n$ is dense. since $C[0, 1] - \bigcup_{n=1}^\infty
    S_n \subset E$ by (a), $E$ is also dense.

    \end{enumerate}
    
    \section*{Problem 7}
    Let $k \le \frac{nt}{\delta}$ be the biggest $k$. Since $x_n$ is continuous in $[0, \delta]$,
    \begin{align*}
        x_n(t) - x_0 &= \sum_{j=0}^{k-1} \int_{\frac{j\delta}{n}}^{\frac{(j+1)\delta}{n}}
            x_n^\prime(s)ds + \int_{\frac{k\delta}{n}}^{t} x_n^\prime(s)ds \\
        &= \sum_{j=0}^{k-1} \int_{\frac{j\delta}{n}}^{\frac{(j+1)\delta}{n}}
        F(x_n(\frac{j\delta}{n}))ds + \int_{\frac{k\delta}{n}}^{t} F(x_n(\frac{k\delta}{n}))ds \\
        &= \sum_{j=0}^{k-1} \int_{\frac{j\delta}{n}}^{\frac{(j+1)\delta}{n}}
        F(y_n(s))ds + \int_{\frac{k\delta}{n}}^{t} F(y_n(s))ds \\
        &= \int_{0}^{t} F(y_n(s))ds \\
    \end{align*}
    We prove by induction to show that $|x_n(t)|$ is uniformly bounded by 
    $\max\{|x_0+r|, |x_0-r|\}$, which is equivalent to say $\abs{x_n(t) - x_0} \le r$
    for any $n\in \mathbb{N}, t \in [0, \delta]$.
    Base case: $|x_n(0) - x_0| = 0 < r$.
    Suppose for any $n \in \mathbb{N}$, $t \le \frac{j\delta}{n}$, we have 
    $|x_n(t) - x_0| \le tM$. When $t \in (\frac{j\delta}{n}, \frac{(j+1)\delta}{n}]$,
    we have 
    \begin{align*}
        x_n(t) &= x_n(\frac{j\delta}{n}) + (t - \frac{j\delta}{n}) F(x_n(\frac{j\delta}{n})) \\
    \end{align*}
    Since $M := \sup_{x \in [x_0 - r, x_0 + r]} |F(x)|$ and  
    $\abs{x_n(\frac{j\delta}{n}) - x_0} \le \frac{j\delta}{n}M$
     by hypothesis, $F(x_n(\frac{j\delta}{n})) \le M$. Then 
    \begin{align*}
        |x_n(t)-x_0| &= \abs{x_n(\frac{j\delta}{n}) + 
                (t - \frac{j\delta}{n}) F(x_n(\frac{j\delta}{n})) - x_0} \\
            &\le
             \abs{x_n(\frac{j\delta}{n})-x_0} + \abs{F(x_n(\frac{j\delta}{n})) 
                (t - \frac{j\delta}{n})} \\
            &\le \frac{j\delta}{n}M + M(t - \frac{j\delta}{n}) = tM
    \end{align*}
    So $x_n(t)$ is uniformly bounded.
    
    By the proof above, $F(x_n(\frac{j\delta}{n})) \le M$ for any $j=1,2,\ldots,n-1$, 
    therefore $|x_n^\prime(t)|$ is bounded by $M$. Hence for any $\ve > 0$, there exists 
    $c = \frac{\ve}{2M}$ such that whenever $t, s \in [0, \delta]$ and $|t-s| < c$, then
    \begin{align*}
        \abs{x_n(t) - x_n(s)} \le M |t-s| = \ve / 2 < \ve
    \end{align*}
    Therefore $x_n(t)$ is also equicontinuous on $[0, \delta]$.
    By Arzela-Ascoli theorem, $\{x_n(t)\}_{n=1}^\infty$ has a converging subsequence.

    \section*{Problem 8}
    To prove that there exists a subsequence of $f$ that converges uniformly on every compact
    sets $K \subset R$, it suffices to prove that this subsequence converges uniformly 
    on $K_n = [-n, n]$ for any $n \in N$. Because any compact sets on $R$ is close and bounded,
    so it will be a subset of $K_n$ for some $n$.

    For $n = 1$, since $H(x), K(x)$ are a continuous funtions on a closed interval,
    they are all bounded by $M_h(1), M_k(1)$. Thus $f_k(x), f_k^\prime(x)$ is uniformly bounded on 
    $[-1, 1]$. According to exercise 4.21, $f_k(x)$ is equicontinuous on $[-1, 1]$. By 
    Arzela Ascoli, there exist a subsequence $f_k^1(x)$ that converges uniformly on $[-1, 1]$.

    For $n = 2$, consider only $f_k^1(x)$, which is still uniformly bounded and equicontinuous
    on $[-2,2]$. Apply A-A again, and we get $f_k^2(x)$ that converges uniformly on $[-2, 2]$.

    We proceed with $n \to \infty$. Then we extract $f_1^1, f_2^2, f_3^3, \ldots$ and we claim
    that this sequence uniformly converges in $[-n, n]$ for any $n \in N$. 
    
    Explain:
    For a specific $n$, omitting the former of the sequence, starting from $n$ : 
    $f_n^n, f_{n+1}^{n+1} \ldots$. This forms a subsequence of $f_k^n$, thus it converges 
    uniformly on $[-n, n]$. Hence this sequence uniformly converges on 
    any compact set $K \subset R$.

    For every $x \in R$, $x \in [-m, m]$ for some $m$, thus the sequence converges at $x$,
    so it converges pointwise.

    
\end{document}